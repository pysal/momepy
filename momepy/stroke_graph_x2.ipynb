{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3867e2cf",
   "metadata": {},
   "source": [
    "# Stroke graph generated twice...\n",
    "\n",
    "and then merging methods.\n",
    "\n",
    "(Also preparing for tests.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2345ab9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import geopandas as gpd\n",
    "import momepy\n",
    "import networkx as nx\n",
    "from itertools import combinations, product\n",
    "from shapely import LineString\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d08f78b",
   "metadata": {},
   "source": [
    "* read in gdf of linestrings\n",
    "* explode\n",
    "* mm remove false nodes\n",
    "* mm gdf to nx, primal, preserving index\n",
    "* mm nx to gdf only of lines\n",
    "* run coins (pass angle_threshold and flow_mode, defaults!)\n",
    "* from coins get .stroke_attribute() and .stroke_gdf()\n",
    "* add \"rep_point\" to .stroke_gdf()\n",
    "* add \"edge_indeces\" column to stroke gdf (anvy version)\n",
    "* for each edge, add \"stroke_id\" as attribute to graph (clse version)\n",
    "* create stroke graph (anvy version)\n",
    "* add nodes to stroke graph (anvy version)\n",
    "* adding edges to stroke graph (clse version)\n",
    "* compute metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb8c7e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_interior_angle(a, b):\n",
    "    '''\n",
    "    Helper function for ``make_stroke_graph()``.\n",
    "    Computes interior angle between two LineString segments\n",
    "    (interpreted as 2-dimensional vectors)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a, b: numpy.ndarray\n",
    "    '''\n",
    "    angle = np.rad2deg(np.arccos(np.dot(a, b)/(np.linalg.norm(a) * np.linalg.norm(b))))\n",
    "    if angle > 90:\n",
    "        print(\"over 90\")\n",
    "        angle = 180 - angle\n",
    "    else:\n",
    "        print(\"under 90\")\n",
    "    return angle\n",
    "\n",
    "def _get_end_segment(linestring, point):\n",
    "    '''\n",
    "    Helper function for ``make_stroke_graph()``.\n",
    "    Returns the first or last two-Point segment of a LineString.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    linestring: shapely.LineString\n",
    "    point: list\n",
    "        A list of length 2 containing the coordinates of either\n",
    "        the first or the last point on the linestring.\n",
    "    '''\n",
    "    point = tuple(point)\n",
    "    coords = list(linestring.coords)\n",
    "    assert point in coords, \"point not on linestring!\"\n",
    "    if point == coords[0]:\n",
    "        geom = [np.array(val) for val in linestring.coords[:2]]\n",
    "    elif point == coords[-1]:\n",
    "        geom = [np.array(val) for val in linestring.coords[-2:]]\n",
    "    else:\n",
    "        raise ValueError(\"point is not an endpoint of linestring!\")\n",
    "    return np.array(geom[0] - geom[1])\n",
    "\n",
    "def make_stroke_graph(gdf, compute_metrics=True, angle_threshold=0, flow_mode=False):\n",
    "    '''\n",
    "    Creates the stroke graph of a street network. The stroke graph is similar to, but not identical with,\n",
    "    the dual graph. In the stroke graph, each stroke (see ``momepy.COINS``) is a node; and each intersection\n",
    "    between two strokes is an edge.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gdf: GeoDataFrame\n",
    "        A GeoDataFrame containing edge geometry of a street network.\n",
    "    compute_metrics: bool (default True)\n",
    "        if True, computes stroke graph metrics and adds them as node attributes.\n",
    "        The following metrics are computed: betweenness centrality, closeness centrality, \n",
    "        degree, connectivity, access, orthogonality, spacing. # TODO add references here\n",
    "    angle_threshold: int, float (default 0), units: degrees\n",
    "        Passed on to ``momepy.COINS()``\n",
    "     flow_mode : bool, default False\n",
    "        Passed on to ``momepy.COINS()``\n",
    "    ''' \n",
    "\n",
    "    # remove false nodes (interstitital nodes of degree 2)\n",
    "    gdf = momepy.remove_false_nodes(gdf)\n",
    "\n",
    "    # make primal graph\n",
    "    graph = momepy.gdf_to_nx(\n",
    "        gdf, \n",
    "        preserve_index=True, # !! preserving index needed for unambiguous mapping to coins!\n",
    "        approach=\"primal\"\n",
    "    )\n",
    "\n",
    "    # get momempy lines of graph\n",
    "    lines = momepy.nx_to_gdf(\n",
    "        graph,\n",
    "        points=False,\n",
    "        lines=True\n",
    "    )\n",
    "\n",
    "    # get COINS of graph lines\n",
    "    coins = momepy.COINS(lines, angle_threshold=angle_threshold, flow_mode=flow_mode)\n",
    "\n",
    "    # get strokes attributes from coins\n",
    "    stroke_attribute = coins.stroke_attribute()\n",
    "\n",
    "    # get strokes gdf fro coins\n",
    "    stroke_gdf = coins.stroke_gdf()\n",
    "\n",
    "    # add representative point to stroke_gdf (for later visualization)\n",
    "    stroke_gdf[\"rep_point\"] = stroke_gdf.geometry.apply(lambda x: x.interpolate(0.5, normalized=True))\n",
    "\n",
    "    # add stroke_id column\n",
    "    stroke_gdf[\"stroke_id\"] = stroke_gdf.index\n",
    "\n",
    "    # add column containing indeces of edges comprising each stroke \n",
    "    # (using COINS.stroke_attribute to map into ID defined in lines gdf)\n",
    "    stroke_gdf[\"edge_indeces\"] = stroke_gdf.stroke_id.apply(\n",
    "        lambda x: list(stroke_attribute[stroke_attribute==x].index)\n",
    "    )\n",
    "\n",
    "    # Add stroke ID to each edge on (primal) graph\n",
    "    nx.set_edge_attributes(\n",
    "        G=graph, \n",
    "        values={e: int(stroke_attribute[graph.edges[e][\"index_position\"]]) for e in graph.edges},\n",
    "        name=\"stroke_id\"\n",
    "    )\n",
    "\n",
    "    # make stroke graph\n",
    "    stroke_graph = nx.Graph()\n",
    "\n",
    "    # copy crs and approach attributes from \"original\" primal graph\n",
    "    stroke_graph.graph[\"crs\"] = graph.graph[\"crs\"]\n",
    "    stroke_graph.graph[\"approach\"] = graph.graph[\"approach\"]\n",
    "\n",
    "    # add nodes to stroke graph\n",
    "    stroke_graph.add_nodes_from(\n",
    "        [\n",
    "            (\n",
    "                row.stroke_id, \n",
    "                {\n",
    "                    \"edge_indeces\": row.edge_indeces,\n",
    "                    \"geometry\": row.rep_point, # \"geometry\" is the representative point (for viz later)\n",
    "                    \"stroke_geometry\": row.geometry,\n",
    "                    \"stroke_length\": row.geometry.length,\n",
    "                    \"x\": row.rep_point.xy[0][0],\n",
    "                    \"y\": row.rep_point.xy[1][0],\n",
    "                    \"connectivity\": 0\n",
    "                }\n",
    "            ) for _, row in stroke_gdf.iterrows()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # add edges to stroke graph\n",
    "    for n in graph.nodes:\n",
    "        strokes_present = [graph.edges[e][\"stroke_id\"] for e in graph.edges(n, keys=True)]\n",
    "        # If strokes intersecting, add the edge if not already present\n",
    "        if len(set(strokes_present)) > 1:\n",
    "            for u, v in combinations(set(strokes_present), 2):\n",
    "                # Find all edges touching the node for both strokes checked\n",
    "                edges_u = [e for e in graph.edges(n, keys=True) if graph.edges[e][\"stroke_id\"] == u]\n",
    "                edges_v = [e for e in graph.edges(n, keys=True) if graph.edges[e][\"stroke_id\"] == v]\n",
    "                angle_list = []\n",
    "                angle_dict = {}\n",
    "                # Choose the smallest list as number of angles kept\n",
    "                chosen, other = sorted([edges_u, edges_v], key=len)\n",
    "                # Find the angles\n",
    "                for ce, oe in list(product(chosen, other)):\n",
    "                    point = [graph.nodes[n][\"x\"], graph.nodes[n][\"y\"]]\n",
    "                    gc = _get_end_segment(graph.edges[ce][\"geometry\"], point)\n",
    "                    go = _get_end_segment(graph.edges[oe][\"geometry\"], point)\n",
    "                    if ce in angle_dict:\n",
    "                        print(gc, go)\n",
    "                        angle_dict[ce].append(_get_interior_angle(gc, go))\n",
    "                    else:\n",
    "                        angle_dict[ce]= [_get_interior_angle(gc, go)]\n",
    "                # Keep the smallest angles\n",
    "                angle_list = [min(angle_dict[ekey]) for ekey in angle_dict]\n",
    "                if stroke_graph.has_edge(u, v):\n",
    "                    stroke_graph.edges[u, v][\"angles\"] += angle_list\n",
    "                    stroke_graph.edges[u, v][\"number_connections\"] = len(stroke_graph.edges[u, v][\"angles\"])\n",
    "                else:\n",
    "                    edge_geometry = LineString(\n",
    "                        [\n",
    "                            stroke_graph.nodes[u][\"geometry\"],\n",
    "                            stroke_graph.nodes[v][\"geometry\"]\n",
    "                        ]\n",
    "                    )\n",
    "                    stroke_graph.add_edge(\n",
    "                        u,\n",
    "                        v,\n",
    "                        geometry=edge_geometry,\n",
    "                        angles=angle_list,\n",
    "                        number_connections=len(angle_list),\n",
    "                    )\n",
    "\n",
    "    # once stroke graph is created, compute metrics\n",
    "    if compute_metrics:\n",
    "        \n",
    "        # add stroke betweenness\n",
    "        nx.set_node_attributes(\n",
    "            stroke_graph,\n",
    "            nx.betweenness_centrality(stroke_graph),\n",
    "            \"stroke_betweenness\"\n",
    "        )\n",
    "\n",
    "        # add stroke closeness\n",
    "        nx.set_node_attributes(\n",
    "            stroke_graph,\n",
    "            nx.closeness_centrality(stroke_graph),\n",
    "            \"stroke_closeness\"\n",
    "        )\n",
    "\n",
    "        # add stroke degree\n",
    "        nx.set_node_attributes(\n",
    "            stroke_graph,\n",
    "            dict(nx.degree(stroke_graph)),\n",
    "            \"stroke_degree\"\n",
    "        )\n",
    "\n",
    "        # add derived metrics\n",
    "        for n in stroke_graph.nodes:\n",
    "            stroke_graph.nodes[n][\"stroke_connectivity\"] = sum([stroke_graph.edges[e][\"number_connections\"] for e in stroke_graph.edges(n)])\n",
    "            stroke_graph.nodes[n][\"stroke_access\"] = stroke_graph.nodes[n][\"stroke_connectivity\"] - stroke_graph.nodes[n][\"stroke_degree\"]\n",
    "            angles = [val for e in stroke_graph.edges(n) if stroke_graph.edges[e][\"angles\"] for val in stroke_graph.edges[e][\"angles\"]]\n",
    "            stroke_graph.nodes[n][\"stroke_orthogonality\"] = sum(angles) / stroke_graph.nodes[n][\"stroke_connectivity\"]\n",
    "            stroke_graph.nodes[n][\"stroke_spacing\"] = stroke_graph.nodes[n][\"stroke_length\"] / stroke_graph.nodes[n][\"stroke_connectivity\"]\n",
    "\n",
    "    return stroke_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf48897f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[172.43389124 200.04361864] [-21.00598791  53.213871  ]\n",
      "[-67.53753506 169.20194522] [ -36.70203611 -143.20022765]\n",
      "[20.67202944 -5.31082693] [ -36.70203611 -143.20022765]\n",
      "[138.74861333  50.07089695] [ -36.70203611 -143.20022765]\n",
      "[-10.17460146 -11.36771275] [-12.85740118  23.9677018 ]\n",
      "[-12.94645678 -53.64521433] [-12.46778297   2.95038997]\n",
      "[ -2.52695244 -10.77759593] [-12.46778297   2.95038997]\n",
      "[14.41587406 -2.08266641] [ 48.81359671 196.04599555]\n",
      "[-11.4770395    0.83306642] [ 48.81359671 196.04599555]\n",
      "[-5.34333556 14.05794796] [186.99448064  72.66718594]\n",
      "[-3.71807099  9.75380008] [186.99448064  72.66718594]\n",
      "[186.99448064  72.66718594] [-34.82073672  95.5406763 ]\n",
      "[137.64655037  52.36093896] [-34.82073672  95.5406763 ]\n",
      "[-103.43807085 -118.06598393] [-56.182947    46.47685819]\n",
      "[ -43.24762217 -184.31034761] [-17.16546548   4.16515838]\n",
      "[ -3.33958472 -14.3871424 ] [-17.16546548   4.16515838]\n",
      "[-113.35663747 -124.5378657 ] [-44.58345606  42.29401113]\n",
      "[-8.56046884 12.61777878] [23.77784324 90.1993154 ]\n",
      "[ 14.37134626 -13.50291124] [23.77784324 90.1993154 ]\n",
      "[-28.3530743   5.0675803] [ 33.50716673 135.90379807]\n",
      "[-16.31943735   3.60978511] [ 33.50716673 135.90379807]\n",
      "[-13.83701271   3.26276734] [ 44.83949089 196.24962944]\n",
      "[-10.35271265 -11.5758026 ] [-11.09855323  10.0485472 ]\n"
     ]
    }
   ],
   "source": [
    "# read in toy graph (Bubenec)\n",
    "gdf = gpd.read_file(momepy.datasets.get_path(\"bubenec\"), layer=\"streets\")\n",
    "\n",
    "stroke_graph = make_stroke_graph(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ead622d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "under 90\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(71.56505117707799)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_get_interior_angle([0,1],[3,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4833829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "linestring = LineString([[0,0],[0,1],[0,2],[0,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2fe629ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"100.0\" height=\"100.0\" viewBox=\"-0.12 -0.12 1.2400000000000002 3.24\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,3.0)\"><polyline fill=\"none\" stroke=\"#66cc99\" stroke-width=\"0.06480000000000001\" points=\"0.0,0.0 0.0,1.0 0.0,2.0 0.0,3.0 1.0,3.0\" opacity=\"0.8\" /></g></svg>"
      ],
      "text/plain": [
       "<LINESTRING (0 0, 0 1, 0 2, 0 3, 1 3)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linestring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e752d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "linestring = LineString(\n",
    "    [\n",
    "        [0,0],\n",
    "        [0,1],\n",
    "        [0,2],\n",
    "        [0,3],\n",
    "        [1,3]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eae1c504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.,  0.])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_get_end_segment(linestring, [1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d242cf59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "momepy_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
